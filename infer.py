from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# ì„¤ì •
base_model_path = "./llama-3-Korean-Bllossom-8B"
adapter_prompts = {
    "Empathy": {
        "path": "./empathy-final",
        "prompt": """ë‹¹ì‹ ì€ ê³µê°(Empathy) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\nëª©í‘œ: ë‚´ë‹´ìì˜ ê°ì •ì„ ê³µê°í•˜ê³  ì´í•´í•˜ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\nê·œì¹™:\n1) ì¡´ëŒ“ë§ ìœ ì§€.\n2) ì§ˆë¬¸ ê¸ˆì§€.\n\në‚´ë‹´ì: ìš”ì¦˜ ë„ˆë¬´ ë¬´ê¸°ë ¥í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.\nìƒë‹´ì‚¬:"""
    },
    "Identification": {
        "path": "./identification-final",
        "prompt": """ë‹¹ì‹ ì€ ì‹ë³„(Identification) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\nëª©í‘œ: ë‚´ë‹´ìì˜ ë¹„í•©ë¦¬ì  ìƒê°ì„ ì•Œë ¤ì£¼ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\nê·œì¹™:\n1) ì§ˆë¬¸ ê¸ˆì§€.\n2) ì¡´ëŒ“ë§ ìœ ì§€.\n3) ë‚´ë‹´ìì˜ ì´ì•¼ê¸°ì—ì„œ ë¹„í•©ë¦¬ì  ìƒê°ì„ ì•Œë ¤ì£¼ê¸°.\n\në‚´ë‹´ì: ìš”ì¦˜ ë„ˆë¬´ ë¬´ê¸°ë ¥í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.\nìƒë‹´ì‚¬:"""
    },
    "Strategy": {
        "path": "./strategy-final",
        "prompt": """ë‹¹ì‹ ì€ ì „ëµ(Strategy) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\nëª©í‘œ: ë‚´ë‹´ìì˜ ê³ ë¯¼ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ í•´ê²° ì „ëµì´ë‚˜ ì¡°ì–¸ì„ ì œì‹œí•©ë‹ˆë‹¤.\nê·œì¹™:\n1) ì¡´ëŒ“ë§ ìœ ì§€.\n2) ì§ˆë¬¸ ê¸ˆì§€.\n3) ë‚´ë‹´ìì˜ ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì  ì „ëµ, ì‹¤ì²œ ë°©ì•ˆ, ì¡°ì–¸ì„ ì œì‹œí•˜ê¸°.\n\në‚´ë‹´ì: ìš”ì¦˜ ë„ˆë¬´ ë¬´ê¸°ë ¥í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.\nìƒë‹´ì‚¬:"""
    },
    "Reflection": {
        "path": "./reflection-final",
        "prompt": """ë‹¹ì‹ ì€ ë°˜ì˜(Reflection) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\nëª©í‘œ: ë‚´ë‹´ìì˜ ê°ì •, ìƒê°, ê²½í—˜ì„ ìš”ì•½í•˜ê±°ë‚˜ ë˜ì§šì–´ì£¼ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\nê·œì¹™:\n1) ì§ˆë¬¸ ê¸ˆì§€.\n2) ì¡´ëŒ“ë§ ìœ ì§€.\n3) ë‚´ë‹´ìì˜ ê°ì •, ìƒê°, ê²½í—˜ì„ ìš”ì•½í•˜ê±°ë‚˜ ë˜ì§šì–´ì£¼ê¸°.\n\në‚´ë‹´ì: ìš”ì¦˜ ë„ˆë¬´ ë¬´ê¸°ë ¥í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.\nìƒë‹´ì‚¬:"""
    },
    "Encouragement": {
        "path": "./encouragement-final",
        "prompt": """ë‹¹ì‹ ì€ ê²©ë ¤(Encouragement) ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\nëª©í‘œ: ë‚´ë‹´ìì˜ ê³ ë¯¼ì— ëŒ€í•´ ê²©ë ¤í•˜ê³  ì‘ì›í•˜ëŠ” ëŒ€í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\nê·œì¹™:\n1) ì¡´ëŒ“ë§ ìœ ì§€.\n2) ì§ˆë¬¸ ê¸ˆì§€.\n\në‚´ë‹´ì: ìš”ì¦˜ ë„ˆë¬´ ë¬´ê¸°ë ¥í•˜ê³  ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš”.\nìƒë‹´ì‚¬:"""
    }
}

# tokenizer + base model ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(base_model_path, use_fast=False)
base_model = AutoModelForCausalLM.from_pretrained(
    base_model_path,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ì¶”ë¡  í•¨ìˆ˜
def infer_with_adapter(base_model, adapter_path, prompt):
    model = PeftModel.from_pretrained(base_model, adapter_path, device_map="auto")
    model.eval()

    input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to(model.device)
    with torch.no_grad():
        output_ids = model.generate(
            input_ids,
            max_new_tokens=150,
            do_sample=True,
            top_p=0.9,
            temperature=0.7
        )
    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    return output_text.split("ìƒë‹´ì‚¬:")[-1].strip()

# ê° agentì— ëŒ€í•´ ì¶”ë¡  ì‹¤í–‰
responses = {}
for agent, info in adapter_prompts.items():
    response = infer_with_adapter(base_model, info["path"], info["prompt"])
    responses[agent] = response

# ê²°ê³¼ ì¶œë ¥
for agent, text in responses.items():
    print(f"\nğŸŸ© {agent} Agent\n{text}")